{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "## Lab 1\n",
    "\n",
    "Student Name: \n",
    "\n",
    "Student Netid: \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Case study (0 Points - for getting a feedback)\n",
    "- Read [this article](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html) in the New York Times.\n",
    "- Use what we've learned in class and from the book to describe how one could set Target's problem up as a predictive modeling problem, such that they could have gotten the results that they did.  Formulate your solution as a proposed plan using our data science terminology.  Include all the aspects of the formulation that you see as relevant to solving the problem.  Be precise but concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the Target question is: “If we wanted to figure out if a customer is pregnant, even if she didn’t want us to know, can you do that? ”\n",
    "So the predictive modeling is in the Target's problem set to identify wether the woman is pregnant so that they can draw them to Target through some offers.\n",
    "Data Collected : The data analysis process contains: unkown target function, training example, hypothesis set, after those, they can have a learning algorithm and when they encounter error, analysis that and then they get the final hypothsis. For Target case, the data partten which collected by Target have vast amount of data for each people through different means like advertisements. And they also have the detail information for each guest( which contains the age, where you live, salary...) and assign each customer a unique id using which they can trace customers purchase history. Data is therefore collected from various sources. After filtering so that we can ensure there are no duplicate values in the dataset. \n",
    "Machine Learning Model : because the target is the customer would be pregnant or not, so the dataset would be binary.And using supervised learning for this problem.The dataset will have to be divided into training, validation and testing data. Because we have several different features which can also help to increase the model accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Exploring data in the command line (2 Points - one question is optional)\n",
    "For this part we will be using the data file located in `\"data/advertising_events.csv\"`. This file consists of records that pertain to some online advertising events on a given day. There are 4 comma separated columns in this order: `userid`, `timestamp`, `domain`, and `action`. These fields are of type `int`, `int`, `string`, and `int` respectively. Answer the following questions using Linux/Unix bash commands. All questions can be answered in one line (sometimes, with pipes)! Some questions will have many possible solutions. Don't forget that in IPython notebooks you must prefix all bash commands with an exclamation point, i.e. `\"!command arguments\"`.\n",
    "\n",
    "[Hints: You can experiment with whatever you want in the notebook and then delete things to construct your answer later.  You can also use ssh to use the actual bash shell on EC2 (see original directions) and then just paste your answers here. Recall that once you enter the \"!\" then filename completion should work.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. How many records (lines) are in this file? (look up 'wc' command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wc' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wc -l advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many unique users are in this file? (hint: consider the 'cut' command and use pipe operator '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cut' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "!cut -f 1 advertising_events.csv | sort | uniq |wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. List all records for the user with user id 37. (hint: this can be done using 'grep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'grep' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "!grep -f 1 \"37\"\n",
    "!awk -F\",\" '{if($1==\"37\"){print $0}}' advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dealing with data Pythonically (13 Points - 3 points are extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. (1 Point) Download the data set `\"data/ads_dataset.tsv\"` and load it into a Python Pandas data frame called `ads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your code here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "ads = pd.read_csv('ads_dataset.tsv', sep = '\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. (4 Points) Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- For each variable in the data frame calculates the following features:\n",
    "  - `number_nan` to count the number of missing not-a-number values\n",
    "  - Ignoring missing, NA, and Null values:\n",
    "    - `number_distinct` to count the number of distinct values a variable can take on\n",
    "    - `mean`, `max`, `min`, `std` (standard deviation), and `25%`, `50%`, `75%` to correspond to the appropriate percentiles\n",
    "- All of these new features should be loaded in a new data frame. Each row of the data frame should be a variable from the input data frame, and the columns should be the new summary features.\n",
    "- Returns this new data frame containing all of the summary information\n",
    "\n",
    "Hint: The pandas `describe()` method returns a useful series of values that can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_NaN</th>\n",
       "      <th>Number_Distinct</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Std</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isbuyer</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.042632</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.202027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_freq</th>\n",
       "      <td>52257</td>\n",
       "      <td>10</td>\n",
       "      <td>1.240653</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.782228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_freq</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1.852777</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.921820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_interval</th>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>0.210008</td>\n",
       "      <td>174.62500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.922016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv_interval</th>\n",
       "      <td>0</td>\n",
       "      <td>5886</td>\n",
       "      <td>5.825610</td>\n",
       "      <td>184.91670</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>17.595442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_buy</th>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>-0.198040</td>\n",
       "      <td>84.28571</td>\n",
       "      <td>-181.9238</td>\n",
       "      <td>4.997792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_visit</th>\n",
       "      <td>0</td>\n",
       "      <td>15135</td>\n",
       "      <td>-10.210786</td>\n",
       "      <td>91.40192</td>\n",
       "      <td>-187.6156</td>\n",
       "      <td>31.879722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_buy</th>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>64.729335</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_visit</th>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>64.729335</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_buy</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.079479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_visit</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.277444</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.447742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_urls</th>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "      <td>86.569343</td>\n",
       "      <td>206.00000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>61.969765</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_checkins</th>\n",
       "      <td>0</td>\n",
       "      <td>4628</td>\n",
       "      <td>720.657592</td>\n",
       "      <td>37091.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1275.727306</td>\n",
       "      <td>127.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>802.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_buy</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.067924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Number_NaN  Number_Distinct        Mean          Max  \\\n",
       "isbuyer                       0                2    0.042632      1.00000   \n",
       "buy_freq                  52257               10    1.240653     15.00000   \n",
       "visit_freq                    0               64    1.852777     84.00000   \n",
       "buy_interval                  0              295    0.210008    174.62500   \n",
       "sv_interval                   0             5886    5.825610    184.91670   \n",
       "expected_time_buy             0              348   -0.198040     84.28571   \n",
       "expected_time_visit           0            15135  -10.210786     91.40192   \n",
       "last_buy                      0              189   64.729335    188.00000   \n",
       "last_visit                    0              189   64.729335    188.00000   \n",
       "multiple_buy                  0                2    0.006357      1.00000   \n",
       "multiple_visit                0                2    0.277444      1.00000   \n",
       "uniq_urls                     0              207   86.569343    206.00000   \n",
       "num_checkins                  0             4628  720.657592  37091.00000   \n",
       "y_buy                         0                2    0.004635      1.00000   \n",
       "\n",
       "                          Min          Std    25%    50%         75%  \n",
       "isbuyer                0.0000     0.202027    0.0    0.0    0.000000  \n",
       "buy_freq               1.0000     0.782228    1.0    1.0    1.000000  \n",
       "visit_freq             0.0000     2.921820    1.0    1.0    2.000000  \n",
       "buy_interval           0.0000     3.922016    0.0    0.0    0.000000  \n",
       "sv_interval            0.0000    17.595442    0.0    0.0    0.104167  \n",
       "expected_time_buy   -181.9238     4.997792    0.0    0.0    0.000000  \n",
       "expected_time_visit -187.6156    31.879722    0.0    0.0    0.000000  \n",
       "last_buy               0.0000    53.476658   18.0   51.0  105.000000  \n",
       "last_visit             0.0000    53.476658   18.0   51.0  105.000000  \n",
       "multiple_buy           0.0000     0.079479    0.0    0.0    0.000000  \n",
       "multiple_visit         0.0000     0.447742    0.0    0.0    1.000000  \n",
       "uniq_urls             -1.0000    61.969765   30.0   75.0  155.000000  \n",
       "num_checkins           1.0000  1275.727306  127.0  319.0  802.000000  \n",
       "y_buy                  0.0000     0.067924    0.0    0.0    0.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getDfSummary(input_data):\n",
    "    # Place your code here\n",
    "    #new a new data frame\n",
    "    #for each variable compute the number_nan, num_distinct, mean, max, min, std\n",
    "    #put the input_data's column to the output_data's index\n",
    "    #put the new features to the output_data's columns\n",
    "    each_row = []\n",
    "    for feature in input_data:\n",
    "        num_nan = np.count_nonzero(input_data[feature].isnull())\n",
    "        num_distinct = input_data[feature].nunique()\n",
    "        des = input_data[feature].describe()[['mean','max','min','std','25%','50%','75%']].values.tolist()\n",
    "        each_row.append([num_nan,num_distinct]+des)\n",
    "    output_data = pd.DataFrame(each_row)\n",
    "    output_data.columns = ['Number_NaN','Number_Distinct','Mean','Max','Min','Std','25%','50%','75%']\n",
    "    output_data.index = [input_data.columns]\n",
    "    return output_data\n",
    "getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "Hint: `use %timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 58.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "%timeit getDfSummary(ads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. (2 Points) Using the results returned from `getDfSummary()`, which fields, if any, contain missing `NaN` values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'buy_freq',)]\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "new_dataframe = getDfSummary(ads)\n",
    "result_missing_values = new_dataframe[new_dataframe.Number_NaN>0]\n",
    "print(result_missing_values._stat_axis.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. (4 Points) For the fields with missing values, does it look like the data is missing at random? Are there any other fields that correlate perfectly, or predict that the data is missing? If missing, what should the data value be? Don't just show code here. Please explain your answer.\n",
    "\n",
    "Hint: create another data frame that has just the records with a missing value. Get a summary of this data frame using `getDfSummary()` and compare the differences. Do some feature distributions change dramatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Number_NaN  Number_Distinct        Mean          Max  \\\n",
      "isbuyer                       0                1    0.000000      0.00000   \n",
      "buy_freq                  52257                0         NaN          NaN   \n",
      "visit_freq                    0               48    1.651549     84.00000   \n",
      "buy_interval                  0                1    0.000000      0.00000   \n",
      "sv_interval                   0             5112    5.686388    184.91670   \n",
      "expected_time_buy             0                1    0.000000      0.00000   \n",
      "expected_time_visit           0            13351   -9.669298     91.40192   \n",
      "last_buy                      0              189   65.741317    188.00000   \n",
      "last_visit                    0              189   65.741317    188.00000   \n",
      "multiple_buy                  0                1    0.000000      0.00000   \n",
      "multiple_visit                0                2    0.255602      1.00000   \n",
      "uniq_urls                     0              207   86.656180    206.00000   \n",
      "num_checkins                  0             4570  721.848518  37091.00000   \n",
      "y_buy                         0                2    0.003024      1.00000   \n",
      "\n",
      "                          Min          Std    25%    50%         75%  \n",
      "isbuyer                0.0000     0.000000    0.0    0.0    0.000000  \n",
      "buy_freq                  NaN          NaN    NaN    NaN         NaN  \n",
      "visit_freq             1.0000     2.147955    1.0    1.0    2.000000  \n",
      "buy_interval           0.0000     0.000000    0.0    0.0    0.000000  \n",
      "sv_interval            0.0000    17.623555    0.0    0.0    0.041667  \n",
      "expected_time_buy      0.0000     0.000000    0.0    0.0    0.000000  \n",
      "expected_time_visit -187.6156    31.239030    0.0    0.0    0.000000  \n",
      "last_buy               0.0000    53.484622   19.0   52.0  106.000000  \n",
      "last_visit             0.0000    53.484622   19.0   52.0  106.000000  \n",
      "multiple_buy           0.0000     0.000000    0.0    0.0    0.000000  \n",
      "multiple_visit         0.0000     0.436203    0.0    0.0    1.000000  \n",
      "uniq_urls             -1.0000    61.996711   30.0   75.0  155.000000  \n",
      "num_checkins           1.0000  1284.504018  126.0  318.0  803.000000  \n",
      "y_buy                  0.0000     0.054904    0.0    0.0    0.000000  \n",
      "                     Number_NaN  Number_Distinct        Mean          Max  \\\n",
      "isbuyer                       0                2    0.042632      1.00000   \n",
      "buy_freq                  52257               10    1.240653     15.00000   \n",
      "visit_freq                    0               64    1.852777     84.00000   \n",
      "buy_interval                  0              295    0.210008    174.62500   \n",
      "sv_interval                   0             5886    5.825610    184.91670   \n",
      "expected_time_buy             0              348   -0.198040     84.28571   \n",
      "expected_time_visit           0            15135  -10.210786     91.40192   \n",
      "last_buy                      0              189   64.729335    188.00000   \n",
      "last_visit                    0              189   64.729335    188.00000   \n",
      "multiple_buy                  0                2    0.006357      1.00000   \n",
      "multiple_visit                0                2    0.277444      1.00000   \n",
      "uniq_urls                     0              207   86.569343    206.00000   \n",
      "num_checkins                  0             4628  720.657592  37091.00000   \n",
      "y_buy                         0                2    0.004635      1.00000   \n",
      "\n",
      "                          Min          Std    25%    50%         75%  \n",
      "isbuyer                0.0000     0.202027    0.0    0.0    0.000000  \n",
      "buy_freq               1.0000     0.782228    1.0    1.0    1.000000  \n",
      "visit_freq             0.0000     2.921820    1.0    1.0    2.000000  \n",
      "buy_interval           0.0000     3.922016    0.0    0.0    0.000000  \n",
      "sv_interval            0.0000    17.595442    0.0    0.0    0.104167  \n",
      "expected_time_buy   -181.9238     4.997792    0.0    0.0    0.000000  \n",
      "expected_time_visit -187.6156    31.879722    0.0    0.0    0.000000  \n",
      "last_buy               0.0000    53.476658   18.0   51.0  105.000000  \n",
      "last_visit             0.0000    53.476658   18.0   51.0  105.000000  \n",
      "multiple_buy           0.0000     0.079479    0.0    0.0    0.000000  \n",
      "multiple_visit         0.0000     0.447742    0.0    0.0    1.000000  \n",
      "uniq_urls             -1.0000    61.969765   30.0   75.0  155.000000  \n",
      "num_checkins           1.0000  1275.727306  127.0  319.0  802.000000  \n",
      "y_buy                  0.0000     0.067924    0.0    0.0    0.000000  \n",
      "nan\n",
      "0.3988389369429984\n",
      "0.005761690797665769\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "# seeing the dataset we can find that the Nan values always happen in [visit_freq]\n",
    "# try to contain the data only with Nan\n",
    "#Then use the getDfSummary to analysis the new dataframe\n",
    "\n",
    "dataframe_only_with_nan = ads[ads[\"buy_freq\"].isnull()]\n",
    "new_dataframe = getDfSummary(dataframe_only_with_nan)\n",
    "old_dataframe = getDfSummary(ads)\n",
    "print(new_dataframe)\n",
    "print(old_dataframe)\n",
    "# according to the staff we did before, we can conclude that [isbuyer] always be 0 or 1, and to look at the daraframe, when [isbuyer] = 0, the [visit_freq] = Nan\n",
    "# so the first thing want to try is to focus on the correlation between [isbuyer] and [buy_freq]\n",
    "# the function I choose is corr() from pandas\n",
    "correlation_between_isbuyer_buy_freq = dataframe_only_with_nan.isbuyer.corr(dataframe_only_with_nan['buy_freq'])\n",
    "print(correlation_between_isbuyer_buy_freq)\n",
    "# but the result show Nan, so what we can do next step is try to figure out all the correlations between each variances using the corr function\n",
    "print(ads.buy_freq.corr(ads['buy_interval']))\n",
    "print(ads.buy_interval.corr(ads['expected_time_buy']))\n",
    "\n",
    "\n",
    "# Conclusion :\n",
    "# So we can only look at the describle charts: [buy_interval] this feature from 1 to 285 in number distinct, and [expected_time_buy] also change from 1 to 348\n",
    "# if [buy_interval] = 0 and [expected_time_buy] = 0, then will high probability the [buy_freq] = Nan\n",
    "# also if youonly look at the chart, we can find that, when [buy_freq]>1, [multiple_buy] is 1. Combining with the former result we have about [isbuyer], when [isbuyer] = 0, [multiple_buy] = 0, we can infor [buy_freq] = nan\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. (4 Points) Which variables are binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'isbuyer',), (u'multiple_buy',), (u'multiple_visit',), (u'y_buy',)]\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "new_dataframe = getDfSummary(ads)\n",
    "result_binary = new_dataframe[new_dataframe.Number_Distinct == 2]\n",
    "print(result_binary._stat_axis.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: $\\LaTeX$ (3 Points)\n",
    "[LaTeX](https://www.latex-project.org/about/) is a high-quality typesetting system which includes features designed for the production of technical and scientific documentation. You can write mathematical equations in jupyter notebooks using LaTeX by surrounding the LaTeX code with `$`. \n",
    "\n",
    "Example: $e^x=\\sum_{i=0}^\\infty \\frac{1}{i!}x^i$\n",
    "\n",
    "Write the following equations in LaTeX!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\.\n",
    "<img src=\"latex_eq_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$J(w;\\lambda) = 1/n*\\sum_{i=1}^{n}(w^Tx_i - y_i)^2 + \\lambda\\Arrowvert w \\Arrowvert^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\.\n",
    "<img src=\"latex_eq_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "sign(w_j):=\\left\\{\n",
    "    \\begin{array}{rcl}\n",
    "    1 &  & {w_j > 0} \\\\\n",
    "    0 &  & {w_j = 0} \\\\\n",
    "    -1 &  & {w_j <0}\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\.\n",
    "<img src=\"latex_eq_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A_{m,n} = \n",
    "\\begin{pmatrix}\n",
    " a_{1,1}   &  a_{1,2}    & \\cdots & a_{1,n} \\\\\n",
    " a_{2,1}   &  a_{2,2}    & \\cdots & a_{2,n} \\\\\n",
    " \\vdots    &  \\vdots     & \\ddots & \\vdots  \\\\\n",
    " a_{m,1}   & a_{m,2}     & \\cdots & a_{m,n} \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
